<!DOCTYPE html>
<html>
 <head>
   <title>Cangxiong Chen</title>
 </head>
 <body>
   <!--
   <nav>
     <ul>
       <li><a href=”/”>Home</a></li>
       <li><a href=”/about”>About</a></li>
       <li><a href=”/resume”>Resume</a></li>
       <li><a href=”/blog”>Blog</a></li>
     </ul>
   </nav>
   -->
   
   <div class=”container”>
     <div class=”blurb”>
       <h2>Cangxiong Chen </h2>
       <h3>About</h3>
       <p>My name is Cangxiong Chen or 陈仓雄 (in Chinese).
       I am a Mathematical Innovation Research Associate at the <a href="https://imibath.ac.uk/">Institute for Mathematical Innovation</a>, <a href="https://www.bath.ac.uk/">University of Bath</a>. </p>
       
       <p>I'm interested in mathematics of machine learning and how we can build learning algorithms with privacy, fairness, robustness and generalisability. One of the problems I'm looking at is how we can design learning algorithms for image or video processing with differential privacy using tools from compressed sensing and dynamical systems. </p>
       <p>
           Before joining the University of Bath, I worked for startups in Cambridge UK and in Beijing China, where I used machine learning and statistical methods to model consumer behaviour and used that knowledge to improve pricing models and recommendation systems.
       </p>
       <p>
           I got my PhD in number theory from the <a href="https://www.maths.cam.ac.uk/">University of Cambridge</a> under the supervision of <a href="https://www.dpmms.cam.ac.uk/~ajs1005/">Tony Scholl</a>. In my <a href="https://www.repository.cam.ac.uk/bitstream/handle/1810/306109/PhDthesis_CangxiongChen.pdf?sequence=3">thesis</a>, I generalised Kronecker limit formula to arbitrary number fields. I got my MPhil and Bachelor’s degrees from the <a href="https://hkumath.hku.hk/web/index.php">University of Hong Kong</a> . In my <a href="https://hub.hku.hk/handle/10722/144805">MPhil thesis</a> supervised by <a href="https://hkumath.hku.hk/~nmok/">Ngaiming Mok</a>, I proposed a differential geometric approach to study rational points on elliptic curves over function fields.
       </p>
       <h3>Contact</h3>
       <p>cc2458 [AT] bath [DOT] ac [DOT] uk</p>
       <p>
           <a href="https://scholar.google.com/citations?user=IKbCKlIAAAAJ&hl=en&oi=ao">Google Scholar</a>,
           <a href="https://github.com/CangxiongChen">Github</a>,
           <a href="https://www.linkedin.com/in/cangxiong-chen-28414013/">LinkedIn</a>,
           <a href="https://twitter.com/antonio_cxchen">Twitter</a>
       </p>
       <!-- <h3>News</h3> -->
       <h3>Selected publications</h3>
       <p>The full list can be found in my <a href="https://scholar.google.com/citations?user=IKbCKlIAAAAJ&hl=en&oi=ao">Google Scholar</a> page.</p>
     </div>
   </div>
   <footer>
   <ul>
     <li><a href="https://arxiv.org/abs/2311.14029">Understanding the Vulnerability of CLIP to Image Compression</a>
     Cangxiong Chen, Vinay P. Namboodiri, Julian Padget, 
     <i>NeurIPS Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models</i>, 2023
     </li>
     <li><a href="https://arxiv.org/pdf/2210.13231">Analysing Training-Data Leakage from Gradients through Linear Systems and Gradient Matching</a>
     Cangxiong Chen, Neill D. F. Campbell, 
     <i>The 33rd British Machine Vision Conference (BMVC)</i>, 2022 <a href="https://github.com/CangxiongChen/training-data-leakage">[Code]</a>
     </li>
     <li><a href="https://arxiv.org/pdf/2111.10178">Understanding Training-Data Leakage from Gradients in Neural Networks for Image Classification</a>
     Cangxiong Chen, Neill D. F. Campbell, 
     <i>NeurIPS Workshop 'Privacy in Machine Learning'</i>, 2021, <a href="https://slideslive.com/38970757">[Presentation]</a>
     </li>
   </ul>
   </footer>
 </body>
</html>
